### Introduction to Machine Learning - Andreas C. Müller & Sarah Guido

Essa repo foi criada pra manter todos os estudos que vou fazer para acompanhar o livro **Introduction to Machine Learning - Andreas C. Müller & Sarah Guido**. Caso você decida estudar utilizando meus notebooks, recomendo o [Jupyter Notebook Viewer](https://nbviewer.jupyter.org/github/nicolasbuen/introduction_to_ml/tree/master/), uma vez que o GitHub não funciona bem com arquivos grandes como eles.

* O [primeiro capítulo](https://github.com/nicolasbuen/introduction_to_ml/blob/master/Introduction%20to%20Machine%20Learning%20-%20Cap.%201%20-%20kNN%20e%20Iris%20Dataset.ipynb) é uma introdução aos conceitos iniciais de Machine Learning e utiliza o **Iris dataset** para demonstrar um exemplo de algoritmo de Machine Learning de Classificação (nesse caso, foi o k-NN numa situação multiclass).

* O segundo capítulo é um pouco mais denso por tratar de diversos algoritmos de **supervised learning**. Por isso, decidi separá-lo em duas partes. 
  * A [**primeira parte**](https://github.com/nicolasbuen/introduction_to_ml/blob/master/Introduction%20to%20Machine%20Learning%20-%20Cap.%202%20-%20Supervised%20ML%20Algorithms%20part%201.ipynb) revisa o k-NN e apresenta algoritmos lineares de regressão e classificação, como **Linear Regression**, **Lasso Regression**, **Ridge Regression**, **Logistic Regression** e **Linear Support Vector Machines**. Além disso, são introduzidos algoritmos mais simples como os classificadores **Naive Bayers** (GaussianNB, BernoulliNB e MultiomialNB) e mas também outros complexos como **Decision Trees e seus Ensembles**, como modelos de **Random Forest** e **XGBoost**. Discussões sobre implementação, parametrização, forças e fraquezas de cada um dos algoritmos são feitas nessa parte do livro também.
  * A [**segunda parte**](https://github.com/nicolasbuen/introduction_to_ml/blob/master/Introduction%20to%20Machine%20Learning%20-%20Cap.%202%20-%20Supervised%20ML%20Algorithms%20part%202.ipynb) apresenta alguns algoritmos mais complexos como o **Kernelized SVMs** (polinomial e gaussiano), além de dar algumas pinceladas na intuição por trás de **Redes Neurais e Deep Learning**. Nessa parte, também foram mostrados alguns conceitos relacionados às estimativas de incerteza de previsão de modelos classificadores utilizando funções como a `.predict_proba`, e como interpretá-las.

* O [terceiro capítulo](https://github.com/nicolasbuen/introduction_to_ml/blob/master/Introduction%20to%20Machine%20Learning%20-%20Cap.%203%20-%20Unsupervised%20Learning%20and%20Preprocessing.ipynb) explica alguns dos principais **algoritmos de aprendizado não supervisionado**, focando, em primeiro momento, naqueles para **pré-processamento** (como rescalonanadores) e para **redução de dimensionalidade** (como o PCA, o NMF e o t-SNE) e, na segunda parte do capítulo, nos algoritmos de clusterização. Para o estudo, foram utilizados datasets sintéticos bidimensionais (permitindo visualização) e um dataset do *scikit-learn* com rostos de famosos dos anos 2000. Além da aplicabilidade dos algoritmos, também foram discutidas as dificuldades de avaliação em  modelos não supervisionados de clusterização.

* O [quarto capítulo](https://github.com/nicolasbuen/introduction_to_ml/blob/master/Introduction%20to%20Machine%20Learning%20-%20Cap.%204%20-%20Feature%20Engineering.ipynb) apresenta e explica algumas das técnicas mais comuns de **engenharia de features**: ***binning*, transformações logarítimicas e exponenciais, interações polinomiais** e também os clássicos *encodings* possíveis para variáveis categóricas, como **one-hot-encoding** e **label-encoding**. 

### Bibliografia

*An Introduction to Machine Learning with Python by Andreas C. Müller and Sarah Guido (O’Reilly). Copyright 2017 Sarah Guido and Andreas Müller, 978-1-449-36941-5.*
